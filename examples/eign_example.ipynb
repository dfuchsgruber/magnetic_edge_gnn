{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EIGN: A universal model for edge-level problems\n",
    "\n",
    "Here, we will show you how to use the EIGN model for edge-level problems on a dummy graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eign import EIGNLaplacianConv, EIGNLaplacianWithNodeTransformationConv\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dummy graph\n",
    "\n",
    "Let's create a dummy graph with some directed and undirected edges. We assign each edge with features that have an inherent direction (signed or orientation equivariant features) and some features that do not have an inherent direction (unsigned or orientation invariant features).\n",
    "\n",
    "The signed features are represented with respect to some arbitrary edge orientation through their sign. The edge orientation is encoded through the `edge_index`: If it contains an edge `(u, v)`, signed features are represented relative to the orientation `u -> v`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_signed_features = 3\n",
    "num_unsigned_features = 6\n",
    "\n",
    "# Represent the graph\n",
    "edge_index = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 2],\n",
    "            [2, 3],\n",
    "            [2, 4],\n",
    "            [3, 5],\n",
    "            [5, 0],\n",
    "            [5, 2],\n",
    "        ]\n",
    "    )\n",
    "    .t()\n",
    "    .contiguous()\n",
    ")\n",
    "edge_is_directed = torch.tensor([0, 0, 0, 0, 0, 1, 1], dtype=torch.bool)\n",
    "\n",
    "dummy_features_signed = torch.randn(edge_index.size(1), num_signed_features)\n",
    "dummy_features_unsigned = torch.randn(edge_index.size(1), num_unsigned_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the basic EIGN model\n",
    "\n",
    "We can create an instance of EIGN easily using the `eign` package. It produces both signed outputs (w.r.t. edge orientation) and unsigned outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EIGNLaplacianConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/fuchsgru/magnetic_edge_gnn/magnetic_edge_gnn_public/eign/laplacian.py:88: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  laplacian = (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1007],\n",
       "         [-0.0815],\n",
       "         [ 0.0641],\n",
       "         [ 0.1016],\n",
       "         [ 0.0190],\n",
       "         [-0.0268],\n",
       "         [-0.0208]]),\n",
       " tensor([[ 0.0242,  0.0358, -0.0247, -0.0139,  0.0613],\n",
       "         [-0.0019,  0.0054, -0.0602, -0.0166, -0.0144],\n",
       "         [ 0.0164, -0.0019, -0.0819, -0.0421,  0.0036],\n",
       "         [-0.0058, -0.0603, -0.0896,  0.0203,  0.0134],\n",
       "         [-0.0644,  0.0159,  0.1028,  0.0721, -0.0574],\n",
       "         [-0.0836, -0.0815,  0.0123,  0.0555, -0.0432],\n",
       "         [-0.0831, -0.0596, -0.0013,  0.0864, -0.1022]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        x_signed=dummy_features_signed,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index,\n",
    "        is_directed=edge_is_directed,\n",
    "    )\n",
    "outputs.signed, outputs.unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Orientation Equivariance and Invariance\n",
    "\n",
    "If we change the orientation of *undirected* edges, EIGN's outputs do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the orientation of edges 2 and 4\n",
    "orientation_flipped = torch.zeros(edge_index.size(1), dtype=torch.bool)\n",
    "orientation_flipped[2] = 1\n",
    "orientation_flipped[4] = 1\n",
    "\n",
    "edge_index_flipped = edge_index.clone()\n",
    "edge_index_flipped[:, orientation_flipped] = edge_index_flipped.flip(0)[\n",
    "    :, orientation_flipped\n",
    "]\n",
    "\n",
    "# Represent signed features in this new orientation\n",
    "dummy_features_signed_flipped = dummy_features_signed.clone()\n",
    "dummy_features_signed_flipped[orientation_flipped] = -dummy_features_signed_flipped[\n",
    "    orientation_flipped\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_flipped = model(\n",
    "        x_signed=dummy_features_signed_flipped,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index_flipped,\n",
    "        is_directed=edge_is_directed,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsigned signals which are not represented relative to an orientation remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_flipped.unsigned - outputs.unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signed outputs also are not changed. However, since we changed the orientation of some edges, the sign of the corresponding signed signals have flipped. Intuitively, we have changed the basis in which signed signals are represented. This change is reflected through the sign in both EIGN's inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The signed outputs did not change as well, but are represented w.r.t. the new orientation\n",
    "outputs_flipped_signed_old_orientation = outputs_flipped.signed.clone()\n",
    "# If we reorient them back into the old orientation ...\n",
    "outputs_flipped_signed_old_orientation[\n",
    "    orientation_flipped\n",
    "] = -outputs_flipped_signed_old_orientation[orientation_flipped]\n",
    "# ... we get the same values\n",
    "outputs_flipped_signed_old_orientation - outputs.signed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we change the orientation (=direction) of a *directed* edge, EIGN is sensitive to that and outputs different signed and unsigned features. It can therefore learn to model the direction of directed edges and still represent signed and unsigned edge signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 2, 3, 5, 5],\n",
       "        [1, 2, 3, 4, 5, 0, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the orientation of a directed edge\n",
    "orientation_flipped_directed = torch.zeros(edge_index.size(1), dtype=torch.bool)\n",
    "orientation_flipped_directed[5] = 1\n",
    "\n",
    "edge_index_flipped_directed = edge_index.clone()\n",
    "edge_index_flipped_directed[:, orientation_flipped_directed] = (\n",
    "    edge_index_flipped_directed.flip(0)[:, orientation_flipped_directed]\n",
    ")\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent signed features in this new orientation\n",
    "\n",
    "dummy_features_signed_flipped_directed = dummy_features_signed.clone()\n",
    "dummy_features_signed_flipped_directed[\n",
    "    orientation_flipped_directed\n",
    "] = -dummy_features_signed_flipped_directed[orientation_flipped_directed]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_flipped_directed = model(\n",
    "        x_signed=dummy_features_signed_flipped_directed,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index_flipped_directed,\n",
    "        is_directed=edge_is_directed,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0324, -0.0088,  0.0055, -0.0100,  0.0433],\n",
       "        [ 0.0167, -0.0103, -0.0142,  0.0043,  0.0168],\n",
       "        [ 0.0024, -0.0097, -0.0137, -0.0076, -0.0008],\n",
       "        [ 0.0036, -0.0034, -0.0163, -0.0099,  0.0057],\n",
       "        [-0.0236,  0.0302,  0.0549,  0.0346, -0.0076],\n",
       "        [ 0.0355, -0.0349, -0.0252, -0.0408,  0.0131],\n",
       "        [-0.0321, -0.0141,  0.0447,  0.0194, -0.0304]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the change in orientation (i.e. direction) of the edge breaks orientation invariance ...\n",
    "outputs.unsigned - outputs_flipped_directed.unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0116],\n",
       "        [-0.0009],\n",
       "        [ 0.0024],\n",
       "        [ 0.0063],\n",
       "        [-0.0602],\n",
       "        [ 0.0446],\n",
       "        [ 0.0689]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and also orientation equivariance (w.r.t the old orientation)\n",
    "outputs_flipped_directed_old_orientation = outputs_flipped_directed.signed.clone()\n",
    "outputs_flipped_directed_old_orientation[\n",
    "    orientation_flipped_directed\n",
    "] = -outputs_flipped_directed_old_orientation[orientation_flipped_directed]\n",
    "outputs_flipped_directed_old_orientation - outputs.signed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different variations of EIGN\n",
    "\n",
    "EIGN's Magnetic Laplacian operators also allow representing edge signals at the node level which further increases its expressivity (see our [paper](https://arxiv.org/pdf/2410.16935) for further reading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EIGNLaplacianWithNodeTransformationConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even define your own (learnable) mapping to transform node features that are induced by the Magnetic Edge Laplacian's boundary operators. By default, a `ReLU` is used to introduce some nonlinearity. You can use whatever you want, even a node-level GNN is possible here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_node_feature_transformation(\n",
    "    num_channels_in: int, num_channels_out: int\n",
    ") -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_channels_in, num_channels_out),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_channels_out, num_channels_out),\n",
    "    )\n",
    "\n",
    "\n",
    "model = EIGNLaplacianWithNodeTransformationConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    "    initialize_node_feature_transformation=initialize_node_feature_transformation,\n",
    ").eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magnetic_edge_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
